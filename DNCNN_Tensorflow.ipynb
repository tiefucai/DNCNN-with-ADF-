{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dncnn with Assumed Density Filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "from keras.layers import  Input,Conv2D,Activation\n",
    "from glob import glob\n",
    "import time as time\n",
    "from six.moves import xrange\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import cv2 \n",
    "import scipy.misc as misc\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preprocessor \n",
    "### Build data pipline for the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset_preprocessor(object):\n",
    "    def __init__(self,sess,clean_filepath,noisy_filepath,batch_size,image_shape):\n",
    "        self.clean_filepath = glob(clean_filepath)\n",
    "        self.noisy_filepath = glob(noisy_filepath)\n",
    "        self.batch_size = batch_size\n",
    "        self.image_shape = image_shape ### input should be a 2-element list like:[iamge_width,image_height]\n",
    "        self.sess = sess        \n",
    "        self.train_list = self.clean_filepath + self.noisy_filepath\n",
    "        \n",
    "        def random_int_list(start, stop, length):\n",
    "            start, stop = (int(start), int(stop)) if start <= stop else (int(stop), int(start))\n",
    "            length = int(abs(length)) if length else 0\n",
    "            random_list = []\n",
    "            for i in range(length):\n",
    "                random_list.append(random.randint(start, stop))\n",
    "            return random_list\n",
    "        \n",
    "        def process_image(image):\n",
    "            image_string = tf.read_file(image)\n",
    "            image_decoded = tf.image.decode_image(image_string)\n",
    "            image_decoded.set_shape([None, None, None])\n",
    "            image_resized = tf.image.resize_images(image_decoded, self.image_shape)  \n",
    "            image_converted = tf.cast(image_resized, tf.float32)\n",
    "            return image_converted\n",
    "        \n",
    "        def shuffle_dataset(list1,list2):\n",
    "            res = []\n",
    "            for i in range(400):\n",
    "                seed = random.choice(list2)\n",
    "                list2.remove(seed)\n",
    "                res.append(list1[seed])\n",
    "                res.append(list1[seed + 400])\n",
    "            return res\n",
    "\n",
    "            \n",
    "        shuffle_list = random_int_list(0,399,400)       \n",
    "        self.shuffle_pip = shuffle_dataset(self.train_list,shuffle_list)   \n",
    "        dataset = tf.data.Dataset.from_tensor_slices(self.shuffle_pip)\n",
    "        dataset = dataset.map(process_image,num_parallel_calls = 1)\n",
    "        dataset = dataset.batch(self.batch_size * 2)\n",
    "        dataset = dataset.repeat()\n",
    "        data_iterator = dataset.make_one_shot_iterator() ## format of the pipline likes [clean1,noisy1,clean2,noisy2...]\n",
    "        self.next_data = data_iterator.get_next()\n",
    "\n",
    "    def get_dataset(self):\n",
    "        return self.sess.run(self.next_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build test data pipline for the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testset_preprocessor(object):\n",
    "    def __init__(self,sess,filepath,batch_size,image_shape):\n",
    "        self.filepath = glob(filepath)\n",
    "        self.batch_size = batch_size\n",
    "        self.image_shape = image_shape ### input should be a 2-element list like:[iamge_width,image_height]\n",
    "        self.sess = sess        \n",
    "        \n",
    "        def process_image(image):\n",
    "            image_string = tf.read_file(image)\n",
    "            image_decoded = tf.image.decode_image(image_string)\n",
    "            image_decoded.set_shape([None, None, None])\n",
    "            image_resized = tf.image.resize_images(image_decoded, self.image_shape)  \n",
    "            image_converted = tf.cast(image_resized, tf.float32)\n",
    "            return image_converted\n",
    "\n",
    "                   \n",
    "        dataset = tf.data.Dataset.from_tensor_slices(self.filepath)\n",
    "        dataset = dataset.map(process_image,num_parallel_calls = 1)\n",
    "        dataset = dataset.shuffle(2)\n",
    "        dataset = dataset.batch(self.batch_size)\n",
    "        dataset = dataset.repeat()\n",
    "        data_iterator = dataset.make_one_shot_iterator()\n",
    "        self.next_data = data_iterator.get_next()\n",
    "\n",
    "    def get_dataset(self):\n",
    "        return self.sess.run(self.next_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Normal version DNCNN(with Batch-Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNCNN(object):\n",
    "    def __init__(self,img_channel,batch_size,image_height,image_width,\n",
    "                 stride,padding,epoch_number,filters_number,\n",
    "                 kernel_size,noise_sigma,):\n",
    "        self.sess = tf.Session()\n",
    "        self.img_channel = img_channel\n",
    "        self.batch_size = batch_size\n",
    "        self.image_height = image_height\n",
    "        self.image_width = image_width\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.epoch_number = epoch_number\n",
    "        self.filters_number = filters_number\n",
    "        self.kernel_size = kernel_size\n",
    "        self.noise_sigma = noise_sigma\n",
    "        self.pipline = dataset_preprocessor(sess = self.sess,clean_filepath='data_set/train_clean/*.png',\n",
    "                               noisy_filepath='data_set/train_noisy/*.png',batch_size=self.batch_size,image_shape=[self.image_width,self.image_height])\n",
    "        self.model_build()\n",
    "        \n",
    "    ## model build inside forward propergation and loss \n",
    "    ## Graph\n",
    "    def model_build(self):\n",
    "        \n",
    "        self.noisy_image = tf.placeholder(tf.float32,[None,self.image_height,self.image_width,self.img_channel],name = 'noisy_image')\n",
    "        self.clean_image = tf.placeholder(tf.float32,[None,self.image_height,self.image_width,self.img_channel],name = 'clean_image')\n",
    "        self.train_phase = tf.placeholder(tf.bool)\n",
    "        '''\n",
    "        For other general image denoising tasks, we adopt a larger receptive field and set the depth to be 20      \n",
    "        ''' \n",
    "        ### input layer\n",
    "        with tf.variable_scope('nn_layer1'):\n",
    "            output = tf.layers.conv2d(self.noisy_image, \n",
    "                                      filters = self.filters_number,\n",
    "                                     kernel_size = self.kernel_size,\n",
    "                                     padding = self.padding,\n",
    "                                     strides = self.stride,\n",
    "                                     activation=tf.nn.relu)\n",
    "        \n",
    "        # layer 2 to 19\n",
    "        for i in range(20-2):\n",
    "            with tf.variable_scope('nn_layer' + str(i+2)):\n",
    "                output = tf.layers.conv2d(output,filters = self.filters_number,\n",
    "                                     kernel_size = self.kernel_size,\n",
    "                                     padding = self.padding,\n",
    "                                     strides = self.stride                                 \n",
    "                                     )\n",
    "                output = tf.nn.relu(tf.layers.batch_normalization(output, training=self.train_phase)) \n",
    "        \n",
    "        # layer 20\n",
    "        with tf.variable_scope('nn_layer20'):\n",
    "            noisy_learned = tf.layers.conv2d(output,filters = self.filters_number,\n",
    "                                     kernel_size = self.kernel_size,\n",
    "                                     padding = self.padding,\n",
    "                                    strides = self.stride\n",
    "                                     )    \n",
    "         ### input - noisy image(we gain it from data set)\n",
    "        self.pure_noisy_image = self.noisy_image - self.clean_image\n",
    "        self.denoised_image = self.noisy_image - noisy_learned\n",
    "        self.psnr = tf.image.psnr(self.denoised_image, self.noisy_image, max_val=255.0)[0]\n",
    "        self.loss = tf.reduce_mean(tf.keras.losses.MSE(self.pure_noisy_image,noisy_learned))\n",
    "#         self.loss = (1.0/self.batch_size) * tf.nn.l2_loss(self.pure_noisy_image - noisy_learned)\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=0.001,\n",
    "                                                beta1=0.9,\n",
    "                                                beta2=0.999,\n",
    "                                                epsilon=1e-08,\n",
    "                                                use_locking=False,\n",
    "                                                name='Adam')\n",
    "        self.train_step = self.optimizer.minimize(self.loss)\n",
    "        self.global_init = tf.global_variables_initializer()  ### initializer the variable in every epoch\n",
    "        print(\"[*] initialing the model\")\n",
    "        self.sess.run(self.global_init)\n",
    "        print(\"[*] Saving initialized model\")\n",
    "        self.saver = tf.train.Saver()\n",
    "        self.saver.save(self.sess,\"./save_model/DNCNN_with_BN/DNCNN\")\n",
    "        print(\"[*] Finishing saving and initialing\")\n",
    "        \n",
    "        \n",
    "        ''' \n",
    "        Formally, the averaged mean squared error between the desired residual images and estimated ones from \n",
    "        noisy input can be adopted as the loss function to learn the trainable parameters Θ in DnCNN.\n",
    "        ient-based optimization algorithms and network architecture. Note that two gradient-based optimization algorithms are adopted: \n",
    "        one is the stochastic gradient descent algorithm with momentum (i.e., SGD) and the other one is the Adam algorithm [30].\n",
    "        '''\n",
    "    def train(self):        \n",
    "        ## collect the loss and psnr in certain train_step\n",
    "        tf.summary.scalar('loss', self.loss)\n",
    "        tf.summary.scalar('psnr', self.psnr)\n",
    "        writer = tf.summary.FileWriter('./evaluate', self.sess.graph)\n",
    "        merged = tf.summary.merge_all()       \n",
    "        \n",
    "        ## start training model\n",
    "        print(\"[*] Start training model\")\n",
    "        for epoch in range(self.epoch_number): ## train all data in epoch_number times            \n",
    "            for iteration in range(40): ## each epoch_number has  filepath/self.batch_ize dataset                \n",
    "                cleaned_batch = np.zeros((self.batch_size,self.image_height,self.image_width,self.img_channel),dtype = 'float32')\n",
    "                noised_batch  = np.zeros((self.batch_size,self.image_height,self.image_width,self.img_channel),dtype = 'float32')\n",
    "                train_set = self.pipline.get_dataset()\n",
    "                ind = 0\n",
    "                for index in range(0,2*self.batch_size,2):\n",
    "                    cleaned_batch[ind,:,:,:] = train_set[index] \n",
    "                    noised_batch[ind,:,:,:] = train_set[index+1]\n",
    "                    ind = ind + 1\n",
    "                [_,loss,summary] = self.sess.run([self.train_step,self.loss,merged],feed_dict = {self.clean_image:cleaned_batch, self.noisy_image:noised_batch,self.train_phase: True})\n",
    "#                                                                                             self.noisy_image:noised_batch,\n",
    "#                                                                                                self.train_phase: True})\n",
    "                writer.add_summary(summary, iteration)\n",
    "                if((iteration%10) ==0):\n",
    "                    [psnr,loss] = self.sess.run([self.psnr,self.loss],\n",
    "                                            feed_dict = {self.clean_image:cleaned_batch,\n",
    "                                            self.noisy_image:noised_batch,self.train_phase : False})\n",
    "                    print(\"[*] Saving model\")\n",
    "                    self.saver.save(self.sess,\"save_model/DnCNN_with_BN\",global_step = epoch+1)\n",
    "                    print(\"[*] Training.... : Epoch: \"+ str(epoch) + \", Step: \" + str(iteration) + \", PSNR: \" + str(psnr) + \", LOSS: \" + str(loss))\n",
    "                if(epoch+1 == self.epoch_number):\n",
    "                    self.saver.save(self.sess,\"save_model/DnCNN_with_BN\",global_step = epoch+1)\n",
    "                    [psnr,loss,denoised_image] = self.sess.run([self.psnr,self.loss,self.denoised_image],\n",
    "                                                                  feed_dict = {self.clean_image:cleaned_batch,\n",
    "                                                                self.noisy_image:noised_batch,self.train_phase : False})\n",
    "                    print(\"[*] Final loss and psnr: LOSS: \" + str(loss) + \" PSNR: \" + str(psnr))\n",
    "                    compared = np.concatenate((cleaned_batch[0, :, :, 0], noised_batch[0, :, :, 0], denoised_image[0, :, :, 0]), 1)\n",
    "                    Image.fromarray(np.uint8(compared)).save(str(epoch)+\"_\"+str(iteration)+\".png\")\n",
    "        \n",
    "        \n",
    "        print(\"[*] Finish Training\")\n",
    "\n",
    "    def load_pretrained_model(self,ckpt_dir,meta_dir):\n",
    "        saver = tf.train.Saver()\n",
    "        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "        if ckpt:\n",
    "            saver=tf.train.import_meta_graph(meta_path)\n",
    "            saver.restore(self.sess, ckpt_path)\n",
    "            return saver\n",
    "        else:\n",
    "            print(\"Can't find pretrained model\")\n",
    "    \n",
    "    \n",
    "    def test(self,ckpt_dir,meta_dir,test_filepath,times_of_testing,noisy_sigma): ## input times_of_testing must be a dict\n",
    "                                                                                ## follow such struct {'num_of_images':_ ,'num_of_test_batch':_ }\n",
    "        savevr = load_pretrained_model(ckpt_dir,meta_dir)\n",
    "        assert saver != None , print(\"Error message: No model find\")\n",
    "        test_pip = testset_preprocessor(sess = self.sess,filepath = test_filepath,\n",
    "                                        batch_size = times_of_testing['num_of_images'],\n",
    "                                        image_shape = [self.image_width,self.image_height])\n",
    "        path = \"/test_DNCNN_with_BN\"\n",
    "        for i in range(times_of_testing['num_of_test_batch']):\n",
    "            clean_img = test_pip.get_dataset()\n",
    "            noised_img = cleaned_img + np.random.normal(0, noise_sigma, cleaned_img.shape)\n",
    "            [denoised_img] = self.sess.run([self.denoised_img], feed_dict={self.clean_img: clean_img, self.noised_img: noised_img, self.train_phase: False})\n",
    "            for j in len(clean_img):\n",
    "                compared = np.concatenate((cleaned_img[0, :, :, 0], noised_img[0, :, :, 0], denoised_img[0, :, :, 0]), 1)\n",
    "                cv2.imwrite(os.path.join(path , \"test_DNCNN_with_BN_\" + str(j) + \".png\"), Image.fromarray(np.uint8(compared)))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dncnn = DNCNN(img_channel = 3, batch_size = 10,image_height = 180,image_width = 180,stride = (1,1),padding = 'same', epoch_number = 5,filters_number = 3,kernel_size = (3,3),noise_sigma = 25)\n",
    "dncnn.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Normal DNCNN without Batch-Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNCNN(object):\n",
    "    def __init__(self,img_channel,batch_size,image_height,image_width,\n",
    "                 stride,padding,epoch_number,filters_number,\n",
    "                 kernel_size,noise_sigma,):\n",
    "        self.sess = tf.Session()\n",
    "        self.img_channel = img_channel\n",
    "        self.batch_size = batch_size\n",
    "        self.image_height = image_height\n",
    "        self.image_width = image_width\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.epoch_number = epoch_number\n",
    "        self.filters_number = filters_number\n",
    "        self.kernel_size = kernel_size\n",
    "        self.noise_sigma = noise_sigma\n",
    "        self.pipline = dataset_preprocessor(sess = self.sess,clean_filepath='data_set/train_clean/*.png',\n",
    "                               noisy_filepath='data_set/train_noisy/*.png',batch_size=self.batch_size,image_shape=[self.image_width,self.image_height])\n",
    "        self.model_build()\n",
    "        \n",
    "    ## model build inside forward propergation and loss \n",
    "    ## Graph\n",
    "    def model_build(self):\n",
    "        \n",
    "        self.noisy_image = tf.placeholder(tf.float32,[None,self.image_height,self.image_width,self.img_channel],name = 'noisy_image')\n",
    "        self.clean_image = tf.placeholder(tf.float32,[None,self.image_height,self.image_width,self.img_channel],name = 'clean_image')\n",
    "        self.train_phase = tf.placeholder(tf.bool)\n",
    "        '''\n",
    "        For other general image denoising tasks, we adopt a larger receptive field and set the depth to be 20      \n",
    "        ''' \n",
    "        ### input layer\n",
    "        with tf.variable_scope('nn_layer1'):\n",
    "            output = tf.layers.conv2d(self.noisy_image, \n",
    "                                      filters = self.filters_number,\n",
    "                                     kernel_size = self.kernel_size,\n",
    "                                     padding = self.padding,\n",
    "                                     strides = self.stride,\n",
    "                                     activation=tf.nn.relu)\n",
    "        \n",
    "        # layer 2 to 19\n",
    "        for i in range(20-2):\n",
    "            with tf.variable_scope('nn_layer' + str(i+2)):\n",
    "                output = tf.layers.conv2d(output,filters = self.filters_number,\n",
    "                                     kernel_size = self.kernel_size,\n",
    "                                     padding = self.padding,\n",
    "                                     strides = self.stride,\n",
    "                                    activation=tf.nn.relu\n",
    "                                     )\n",
    "                \n",
    "        \n",
    "        # layer 20\n",
    "        with tf.variable_scope('nn_layer20'):\n",
    "            noisy_learned = tf.layers.conv2d(output,filters = self.filters_number,\n",
    "                                     kernel_size = self.kernel_size,\n",
    "                                     padding = self.padding,\n",
    "                                    strides = self.stride\n",
    "                                     )    \n",
    "         ### input - noisy image(we gain it from data set)\n",
    "        self.pure_noisy_image = self.noisy_image - self.clean_image\n",
    "        self.denoised_image = self.noisy_image - noisy_learned\n",
    "        self.psnr = tf.image.psnr(self.denoised_image, self.noisy_image, max_val=255.0)[0]\n",
    "        self.loss = tf.reduce_mean(tf.keras.losses.MSE(self.pure_noisy_image,noisy_learned))\n",
    "#         self.loss = (1.0/self.batch_size) * tf.nn.l2_loss(self.pure_noisy_image - noisy_learned)\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=0.001,\n",
    "                                                beta1=0.9,\n",
    "                                                beta2=0.999,\n",
    "                                                epsilon=1e-08,\n",
    "                                                use_locking=False,\n",
    "                                                name='Adam')\n",
    "        self.train_step = self.optimizer.minimize(self.loss)\n",
    "        self.global_init = tf.global_variables_initializer()  ### initializer the variable in every epoch\n",
    "        print(\"[*] initialing the model\")\n",
    "        self.sess.run(self.global_init)\n",
    "        print(\"[*] Saving initialized model\")\n",
    "        self.saver = tf.train.Saver(max_to_keep = 10)\n",
    "        self.saver.save(self.sess,\"./save_model/DNCNN_with_BN/DNCNN\")\n",
    "        print(\"[*] Finishing saving and initialing\")\n",
    "        \n",
    "        \n",
    "        ''' \n",
    "        Formally, the averaged mean squared error between the desired residual images and estimated ones from \n",
    "        noisy input can be adopted as the loss function to learn the trainable parameters Θ in DnCNN.\n",
    "        ient-based optimization algorithms and network architecture. Note that two gradient-based optimization algorithms are adopted: \n",
    "        one is the stochastic gradient descent algorithm with momentum (i.e., SGD) and the other one is the Adam algorithm [30].\n",
    "        '''\n",
    "    def train(self):        \n",
    "        ## collect the loss and psnr in certain train_step\n",
    "        tf.summary.scalar('loss', self.loss)\n",
    "        tf.summary.scalar('psnr', self.psnr)\n",
    "        writer = tf.summary.FileWriter('./evaluate', self.sess.graph)\n",
    "        merged = tf.summary.merge_all()       \n",
    "        \n",
    "        ## start training model\n",
    "        print(\"[*] Start training model\")\n",
    "        for epoch in range(self.epoch_number): ## train all data in epoch_number times\n",
    "            \n",
    "            for iteration in range(40): ## each epoch_number has  filepath/self.batch_ize dataset                \n",
    "                cleaned_batch = np.zeros((self.batch_size,self.image_height,self.image_width,self.img_channel),dtype = 'float32')\n",
    "                noised_batch  = np.zeros((self.batch_size,self.image_height,self.image_width,self.img_channel),dtype = 'float32')\n",
    "                train_set = self.pipline.get_dataset()\n",
    "                ind = 0\n",
    "                for index in range(0,2*self.batch_size,2):\n",
    "                    cleaned_batch[ind,:,:,:] = train_set[index] \n",
    "                    noised_batch[ind,:,:,:] = train_set[index+1]\n",
    "                    ind = ind + 1\n",
    "                [_,loss,summary] = self.sess.run([self.train_step,self.loss,merged],feed_dict = {self.clean_image:cleaned_batch, self.noisy_image:noised_batch,self.train_phase: True})\n",
    "#                                                                                             self.noisy_image:noised_batch,\n",
    "#                                                                                                self.train_phase: True})\n",
    "                writer.add_summary(summary, iteration)\n",
    "                if((epoch%10) ==0):\n",
    "                    [psnr,loss] = self.sess.run([self.psnr,self.loss],\n",
    "                                            feed_dict = {self.clean_image:cleaned_batch,\n",
    "                                            self.noisy_image:noised_batch,self.train_phase : False})\n",
    "                    print(\"[*] Training.... : Epoch: \"+ str(epoch) + \", Step: \" + str(iteration) + \", PSNR: \" + str(psnr) + \", LOSS: \" + str(loss))\n",
    "                if(epoch+1 == self.epoch_number):\n",
    "                    print(\"[*] Saving model\")\n",
    "                    self.saver.save(self.sess,\"save_model/DnCNN_with_BN\",global_step = epoch+1)\n",
    "                    [psnr,loss,denoised_image] = self.sess.run([self.psnr,self.loss,self.denoised_image],\n",
    "                                                              feed_dict = {self.clean_image:cleaned_batch,\n",
    "                                                                          self.noisy_image:noised_batch,self.train_phase : False})\n",
    "                    compared = np.concatenate((cleaned_batch[0, :, :, 0], noised_batch[0, :, :, 0], denoised_image[0, :, :, 0]), 1)\n",
    "                    Image.fromarray(np.uint8(compared)).save(str(epoch)+\"_\"+str(iteration)+\".png\")\n",
    "        \n",
    "        \n",
    "        print(\"[*] Finish Training\")\n",
    "\n",
    "    def load_pretrained_model(self,ckpt_dir,meta_dir):\n",
    "        saver = tf.train.Saver()\n",
    "        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "        if ckpt:\n",
    "            saver=tf.train.import_meta_graph(meta_path)\n",
    "            saver.restore(self.sess, ckpt_path)\n",
    "            return saver\n",
    "        else:\n",
    "            print(\"Can't find pretrained model\")\n",
    "    \n",
    "    \n",
    "    def test(self,ckpt_dir,meta_dir,test_filepath,times_of_testing,noisy_sigma): ## input times_of_testing must be a dict\n",
    "                                                                                ## follow such struct {'num_of_images':_ ,'num_of_test_batch':_ }\n",
    "        savevr = load_pretrained_model(ckpt_dir,meta_dir)\n",
    "        assert saver != None , print(\"Error message: No model find\")\n",
    "        test_pip = testset_preprocessor(sess = self.sess,filepath = test_filepath,\n",
    "                                        batch_size = times_of_testing['num_of_images'],\n",
    "                                        image_shape = [self.image_width,self.image_height])\n",
    "        path = \"/test_DNCNN_with_BN\"\n",
    "        for i in range(times_of_testing['num_of_test_batch']):\n",
    "            clean_img = test_pip.get_dataset()\n",
    "            noised_img = cleaned_img + np.random.normal(0, noise_sigma, cleaned_img.shape)\n",
    "            [denoised_img] = self.sess.run([self.denoised_img], feed_dict={self.clean_img: clean_img, self.noised_img: noised_img, self.train_phase: False})\n",
    "            for j in len(clean_img):\n",
    "                compared = np.concatenate((cleaned_img[0, :, :, 0], noised_img[0, :, :, 0], denoised_img[0, :, :, 0]), 1)\n",
    "                cv2.imwrite(os.path.join(path , \"test_DNCNN_with_BN_\" + str(j) + \".png\"), Image.fromarray(np.uint8(compared)))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dncnn = DNCNN(img_channel = 1, batch_size = 40,image_height = 180,image_width = 180,stride = (1,1),padding = 'same', epoch_number = 50,filters_number = 3,kernel_size = (3,3),noise_sigma = 25)\n",
    "dncnn.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Normal DNCNN plus ADF without Batch-Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os, datetime\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from keras.layers import  Input,Conv2D,BatchNormalization,Activation,Subtract\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "import cv2\n",
    "from tensorflow import distributions as dist\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from numbers import Number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADF framework Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normcdf(value, mu=0.0, stddev=1.0):\n",
    "    sinv = (1.0 / stddev) if isinstance(stddev, Number) else stddev.reciprocal()\n",
    "    return 0.5 * (1.0 + tf.math.erf((value - mu) * sinv / np.sqrt(2.0)))\n",
    "\n",
    "def _normal_log_pdf(value, mu, stddev):\n",
    "    var = (stddev ** 2)\n",
    "    log_scale = np.log(stddev) if isinstance(stddev, Number) else torch.log(stddev)\n",
    "    return -((value - mu) ** 2) / (2.0*var) - log_scale - np.log(np.sqrt(2.0*np.pi))\n",
    "\n",
    "\n",
    "def normpdf(value, mu=0.0, stddev=1.0):\n",
    "    return tf.math.exp(_normal_log_pdf(value, mu, stddev))\n",
    "\n",
    "\n",
    "def _lpdn_relu_activation(m, v):\n",
    "#     v = tf.maximum(v, 0.0001)\n",
    "#     v = tf.math.exp(v)\n",
    "#     s = v ** 0.5\n",
    "#     u_out = u * normal.cdf(u / s) + s * normal.prob(u / s)\n",
    "#     v_out = (u + v) * normal.cdf(u / s) + (u * s) * normal.prob(u / s) - u_out ** 2\n",
    "#     v_out = tf.math.log(v_out)\n",
    "    \n",
    "    stddev = tf.math.sqrt(v)\n",
    "    div = m/stddev\n",
    "    pdf = normpdf(div)\n",
    "    cdf = normcdf(div)\n",
    "    out_m = m*cdf + stddev*pdf\n",
    "    out_v = (m ** 2 + v)*cdf + m*stddev*pdf - out_m ** 2\n",
    "    out_v = tf.math.log(out_v)\n",
    "    return out_m, out_v\n",
    "\n",
    "\n",
    "class LPActivation(Activation): ### forward\n",
    "    def __init__(self, activation, **kwargs):\n",
    "        if isinstance(activation, str):\n",
    "            self.activation_name = activation\n",
    "        else:\n",
    "            self.activation_name = activation.__name__\n",
    "        super(LPActivation, self).__init__(activation, **kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        u = inputs[..., 0]\n",
    "        v = inputs[..., 1] ## log\n",
    "        u, v = _lpdn_relu_activation(u, v)\n",
    "        v = tf.math.log(v)\n",
    "        return tf.stack([u,v],-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADF framework Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LPConv2D(Conv2D):\n",
    "    \"\"\"\n",
    "    Propagate distributions over a probabilistic Conv2D layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, filters, kernel_size, **kwargs):\n",
    "        super(LPConv2D, self).__init__(filters, kernel_size, **kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        return super(LPConv2D, self).build(input_shape[:-1])\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        original_output_shape = super(LPConv2D, self).compute_output_shape(input_shape[:-1])\n",
    "        return original_output_shape + (2,)\n",
    "\n",
    "    def assert_input_compatibility(self, inputs):\n",
    "        return super(LPConv2D, self).assert_input_compatibility(inputs[..., 0])\n",
    "\n",
    "    def _conv2d(self, input, kernel):\n",
    "        return K.conv2d(input, kernel, self.strides, self.padding, self.data_format, self.dilation_rate)\n",
    "\n",
    "    def call(self, inputs): ### forward\n",
    "        u = inputs[..., 0]\n",
    "        v = inputs[..., 1]\n",
    "        \n",
    "        v = tf.math.exp(v)\n",
    "        \n",
    "        u = self._conv2d(u, self.kernel)\n",
    "        v = self._conv2d(v, self.kernel ** 2)\n",
    "        \n",
    "        v = tf.math.log(v)\n",
    "        if self.use_bias:\n",
    "            u = K.bias_add(\n",
    "                u,\n",
    "                self.bias,\n",
    "                data_format=self.data_format)\n",
    "\n",
    "        if self.activation is not None:\n",
    "            u, v = _lpdn_relu_activation(u, v)      \n",
    "            v = tf.math.log(v)\n",
    "        return tf.stack([u,v],-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_aug(img, mode=0):\n",
    "\n",
    "    if mode == 0:\n",
    "        return img\n",
    "    elif mode == 1:\n",
    "        return np.flipud(img)\n",
    "    elif mode == 2:\n",
    "        return np.rot90(img)\n",
    "    elif mode == 3:\n",
    "        return np.flipud(np.rot90(img))\n",
    "    elif mode == 4:\n",
    "        return np.rot90(img, k=2)\n",
    "    elif mode == 5:\n",
    "        return np.flipud(np.rot90(img, k=2))\n",
    "    elif mode == 6:\n",
    "        return np.rot90(img, k=3)\n",
    "    elif mode == 7:\n",
    "        return np.flipud(np.rot90(img, k=3))\n",
    "\n",
    "\n",
    "def datagenerator(data_dir = 'data_set/train_clean/*.png',verbose=False):\n",
    "    \n",
    "    file_list = glob(data_dir)  \n",
    "    # initrialize\n",
    "    data = []\n",
    "    # generate patches\n",
    "    for i in range(len(file_list)):\n",
    "        img = cv2.imread(file_list[i])\n",
    "        img = img.resize((180,180))\n",
    "#         img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        final_img = np.zeros((180,180,1,2))\n",
    "        final_img[...,0]=img\n",
    "        final_img[...,1]=img\n",
    "        data.append(final_img)\n",
    "    data = np.array(data,dtype = 'float32')\n",
    "    print('^_^-training data finished-^_^')\n",
    "    return data\n",
    "\n",
    "def train_datagen(epoch_iter=20,epoch_num=1,batch_size=10,data_dir='data_set/train_clean/*.png'):\n",
    "    while(True):\n",
    "        n_count = 0\n",
    "        if n_count == 0:\n",
    "            xs = datagenerator(data_dir)\n",
    "            xs = xs.astype('float32')/255.0\n",
    "            indices = list(range(xs.shape[0]))\n",
    "            n_count = 1\n",
    "        for _ in range(epoch_num):\n",
    "            np.random.shuffle(indices)    # shuffle\n",
    "            for i in range(0, len(indices), batch_size):\n",
    "                batch_x = xs[indices[i:i+batch_size]]\n",
    "#                 print(batch_x.shape)\n",
    "                noise =  np.random.normal(0, 25, batch_x.shape)    # noise\n",
    "                batch_y = batch_x + noise \n",
    "                yield batch_y, batch_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DnCNN(depth, filters, image_channels):\n",
    "    layer_count = 0\n",
    "    inpt = Input(shape=(None, None, image_channels), name='input' + str(layer_count))\n",
    "    # 1st layer, Conv+relu\n",
    "    \n",
    "    layer_count += 1\n",
    "    x = Conv2D(filters=filters, kernel_size=(3, 3), strides=(1, 1), kernel_initializer='Orthogonal', padding='same',\n",
    "               name='conv' + str(layer_count))(inpt)\n",
    "    layer_count += 1\n",
    "    x = Activation('relu', name='relu' + str(layer_count))(x)\n",
    "    # depth-2 layers, Conv+relu\n",
    "    for i in range(depth - 2):\n",
    "        layer_count += 1\n",
    "        x = Conv2D(filters=filters, kernel_size=(3, 3), strides=(1, 1), kernel_initializer='Orthogonal', padding='same',\n",
    "                   use_bias=False, name='conv' + str(layer_count))(x)\n",
    "        layer_count += 1\n",
    "        x = Activation('relu', name='relu' + str(layer_count))(x)\n",
    "    # last layer, Conv\n",
    "    layer_count += 1\n",
    "    x = Conv2D(filters=image_channels, kernel_size=(3, 3), strides=(1, 1), kernel_initializer='Orthogonal',\n",
    "               padding='same', use_bias=False, name='conv' + str(layer_count))(x)\n",
    "    layer_count += 1\n",
    "#     x[...,0] = x1[...,0] - x[...,0]\n",
    "#    \n",
    "    model = Model(inputs=inpt, outputs= x)\n",
    "    return model\n",
    "\n",
    "def convert(keras_model, input_shape=None):\n",
    "    # Create an equivalent probabilistic model.\n",
    "    if input_shape is None:\n",
    "        input_shape = keras_model.layers[0].input_shape[1:] + (2,)\n",
    "        logging.info(\"Inferred input shape: \" + str(input_shape))\n",
    "\n",
    "    lp_input = Input(shape=input_shape)\n",
    "    y = lp_input\n",
    "    for li, l in enumerate(keras_model.layers):\n",
    "        if isinstance(l, Conv2D):\n",
    "            y = LPConv2D(l.filters, l.kernel_size, padding=l.padding, activation=l.activation, name=l.name)(y)\n",
    "        elif isinstance(l, Activation):\n",
    "            y = LPActivation(l.activation, name=l.name)(y)\n",
    "    model = Model(inputs=lp_input, outputs=y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADF_loss(y_true, y_pred):\n",
    "    mean = tf.maximum(0.0001,y_pred[...,0])\n",
    "    print(mean[0])\n",
    "    variance = tf.maximum(0.0001,tf.math.exp(y_pred[...,1]))\n",
    "    #print(variance.shape)\n",
    "    eps = 1e-5\n",
    "    temp = 1/(variance + eps)\n",
    "    output = K.sum(0.5*temp*(y_true[...,0] - mean)**2 + 0.5*tf.math.log(variance + eps))\n",
    "    print(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DnCNN(depth=17,filters=64,image_channels=1)\n",
    "model_lpdn = convert(model)\n",
    "# print(model_lpdn.layers[16].output_shape)\n",
    "# sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_lpdn.compile(optimizer=Adam(0.001), loss=['mse'])\n",
    "history = model_lpdn.fit_generator(train_datagen(batch_size=5),\n",
    "                steps_per_epoch=20, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Above three model all training on the same data set and all implement data augmentation just based on fliping "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaulate each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 180)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
